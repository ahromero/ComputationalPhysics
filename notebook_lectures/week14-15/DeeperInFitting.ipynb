{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 14: Fitting\n",
    "\n",
    "## Objectives:\n",
    "* Cover performance and syntax for general unbinned fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to `pip install probfit` (`--user` if you are not in a virtual environment). `cupy` is used at the end; you'll need `conda install cupy` in an environment. Times are from a 24 core Xeon with a Titan V."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will put our preperation code in a file, and restart the kernel as we go, just to make sure we don't have any interaction between GPU libraries. `likelyhood_answer` is defined to be the numpy value - Note that the reduction can produce lots of round of error if not done properly. I know numpy does, not sure about probfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results: \n",
    "    \n",
    "| Package   | Hardware      | Time per call | Minimize time |\n",
    "|-----------|---------------|---------------|---------------|\n",
    "| Probfit   | 24 core Zeon  | 1.11 s        | 2.23 min      |\n",
    "| Numpy     | 24 core Zeon  | 21.1 ms       | 2.38 s        |\n",
    "| Numba parallel | 24 core Zeon | 11.5 ms   | 1.46 s        |\n",
    "| Numba parallel loop | 24 core Zeon | 3.68 ms | 416 ms     |\n",
    "| GooFit    | Titan V       | 2.30 ms       | 333 ms        |\n",
    "| CUPY      | Titan V       | 2.9 ms        | 491 ms        |\n",
    "| CUPY kernel | Titan V     | 843 µs        | 118 ms        |\n",
    "| CUPY redu | Titan V       | 2.50 ms       | 343 ms        |\n",
    "| PyTorch   | Titan V       | 3.68 ms       | 594 ms        |\n",
    "| TensorFlow static | Titan V | 1.38 ms     | 225 ms        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\r\n",
      "from iminuit import Minuit\r\n",
      "import math\r\n",
      "\r\n",
      "np.random.seed(42)\r\n",
      "\r\n",
      "dist = np.hstack([\r\n",
      "    np.random.normal(loc=1, scale=2., size=500_000),\r\n",
      "    np.random.normal(loc=1, scale=.5, size=500_000)\r\n",
      "])\r\n",
      "\r\n",
      "default_params = dict(\r\n",
      "    f_0=.5,\r\n",
      "    error_f_0=.01,\r\n",
      "    limit_f_0=(0,1),\r\n",
      "\r\n",
      "    mean=1.5,\r\n",
      "    error_mean=.01,\r\n",
      "    limit_mean=(-10,10),\r\n",
      "\r\n",
      "    sigma=.4,\r\n",
      "    limit_sigma=(0,1),\r\n",
      "    error_sigma=.01,\r\n",
      "\r\n",
      "    sigma2=3.,\r\n",
      "    error_sigma2=.01,\r\n",
      "    limit_sigma2=(1,3),\r\n",
      ")\r\n",
      "\r\n",
      "\r\n",
      "class Compare:\r\n",
      "    def __init__(self, value):\r\n",
      "        self.value = value\r\n",
      "        \r\n",
      "    def __eq__(self, other):\r\n",
      "        if other == self.value:\r\n",
      "            return True\r\n",
      "        \r\n",
      "        frac = abs(other - self.value) / self.value\r\n",
      "        print(f'Missed by: {frac:.3}')\r\n",
      "        return frac < .00001\r\n",
      "\r\n",
      "likelyhood_answer = Compare(4976157.922404283)\r\n",
      "\r\n",
      "def run_and_print(minuit):\r\n",
      "    minuit.print_level=0\r\n",
      "    a,b = minuit.migrad()\r\n",
      "    print(\"FCN: {nfcn}\\nis_valid: {is_valid}\\nfval: {fval}\\nedm: {edm}\\n\".format(**a))"
     ]
    }
   ],
   "source": [
    "# it seems read_pretty does not exist anymore\n",
    "# from read_pretty import read_pretty\n",
    "# read_pretty('common.py')\n",
    "!cat common.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data\n",
    "\n",
    "First, we make our data. It's a simple double gaussian with no background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dist, bins='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probfit\n",
    "\n",
    "Now, let's try using probfit to fit the data. First, we have to rename the parameters - probfit merges similar named parameters. I already know that gaussian comes with `x`, `mean`, and `sigma`. We use `AddPdfNorm` to add the pdfs, and they are kept normalized. A new parameter is added, `f_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'probfit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/7rq2vwcx7fd8stfzsvfnz9980000gq/T/ipykernel_60867/778001870.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprobfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'probfit'"
     ]
    }
   ],
   "source": [
    "import probfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_gaussian = probfit.rename(probfit.gaussian, [\"x\", \"mean\", \"sigma2\"])\n",
    "pdf_function = probfit.AddPdfNorm(probfit.gaussian, second_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build an unbinned likelyhood function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbinned_lh = probfit.UnbinnedLH(pdf_function, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unbinned_lh(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "unbinned_lh(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use iMinuit's name based parameter setting interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(unbinned_lh, **default_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's do the fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbinned_lh.draw(minuit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GooFit\n",
    "\n",
    "Let's try that in GooFit. We set up our model in what I view as a more readable but more verbose way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import goofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goofit.GOOFIT_DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = goofit.Observable('x', -10, 10)\n",
    "\n",
    "ds = goofit.UnbinnedDataSet(x)\n",
    "ds.from_matrix([dist], filter=True)\n",
    "\n",
    "mean = goofit.Variable('mean', 1.5, -10, 10)\n",
    "sigma = goofit.Variable('sigma', .4, 0, 1)\n",
    "sigma2 = goofit.Variable('sigma2', 3, 1, 3)\n",
    "f_0 = goofit.Variable('f_0', .5, 0, 1)\n",
    "\n",
    "gauss1 = goofit.GaussianPdf(\"gauss1\", x, mean, sigma)\n",
    "gauss2 = goofit.GaussianPdf(\"gauss2\", x, mean, sigma2)\n",
    "\n",
    "pdf = goofit.AddPdf('pdf', [f_0], [gauss1, gauss2])\n",
    "\n",
    "pdf.fitTo(ds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: On a single thread CPU build, this is about 7-10x faster than probfit. This is on a Titan V GPU, so it's a lot more than that.\n",
    "\n",
    "Plotting is a bit more verbose, but not too bad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, points = pdf.evaluatePdf(x)\n",
    "xs = grid.to_matrix().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(xs, points)\n",
    "ax.hist(dist, bins='auto', density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "Let's try this with Numpy and iMinuit. We could use probfit to make the NLL, but it's much faster to do it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "I originally used numba here, but since this is all done in array form, even parallel Numba is only a small fraction (10-30%) faster on my laptop. On a 24 core Xeon, however... You'll see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * np.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -np.sum(np.log(add(dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Numpy uses a good definition of a sum, while Python's built in sum has rounding point errors. This would be more important if we used fewer bits. Let's compare: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reduction sum:\n",
    "assert -sum(np.log(add(dist, .5, .5, .5, .5))) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check floating point accurate sum:\n",
    "assert -math.fsum(np.log(add(dist, .5, .5, .5, .5))) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much (2-3x) slower if we use this in Minuit\n",
    "# unbinned_lh = probfit.UnbinnedLH(add, dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba\n",
    "\n",
    "Let's use Numba's parallel abilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * np.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -np.sum(np.log(add(dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numba Parallel loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * np.exp(-(x-μ)**2/(2*σ**2))\n",
    "\n",
    "@numba.jit\n",
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def nllp(dist, f_0, mean, sigma, sigma2):\n",
    "    s = 0.0\n",
    "    for i in numba.prange(len(dist)):\n",
    "        s +=  np.log(add(dist[i], f_0, mean, sigma, sigma2))\n",
    "    return -s\n",
    "    \n",
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return nllp(dist, f_0, mean, sigma, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUPY GPU\n",
    "\n",
    "Let's use CUPY on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d_dist = cupy.array(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/cupy.sqrt(2*np.pi*σ**2) * cupy.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -cupy.sum(cupy.log(add(d_dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(nll(.5,.5,.5,.5)) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "float(nll(*np.random.rand(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cupy Custom Kernel\n",
    "\n",
    "Let's go all out and write a CUDA kernel by hand, then call sum on it. We are *almost* ideal here; the only downside is that we make a single temporary 1M element array before summing.\n",
    "\n",
    "We *could* use a reduction kernel, but I don't know if I trust that do not have round off error issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mykernel = cupy.ElementwiseKernel(\n",
    "    'float64 x, float64 f_0, float64 mean, float64 sigma, float64 sigma2',\n",
    "    'float64 z', '''\n",
    "    \n",
    "    double s12 = 2*sigma*sigma;\n",
    "    double s22 = 2*sigma2*sigma2;\n",
    "    \n",
    "    double p = -(x-mean)*(x-mean);\n",
    "    double g = rsqrt(M_PI*s12) * exp(p/s12);\n",
    "    double g2 = rsqrt(M_PI*s22) * exp(p/s22);\n",
    "    \n",
    "    z = log(f_0 * g + (1 - f_0) * g2);\n",
    "        \n",
    "    ''', 'mykernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -cupy.sum(mykernel(d_dist, f_0, mean, sigma, sigma2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(nll(.5,.5,.5,.5)) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "float(nll(*np.random.rand(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rku = cupy.ReductionKernel(\n",
    "    'float64 x, float64 f_0, float64 mean, float64 sigma, float64 sigma2',\n",
    "    'float64 r',\n",
    "    '''\n",
    "    log(     f_0  * rsqrt(2*M_PI*sigma*sigma)   * exp(-(x-mean)*(x-mean)/(2*sigma*sigma)) +\n",
    "        (1 - f_0) * rsqrt(2*M_PI*sigma2*sigma2) * exp(-(x-mean)*(x-mean)/(2*sigma2*sigma2)))\n",
    "    ''',\n",
    "    'a + b',\n",
    "    'r = -a',\n",
    "    '0',\n",
    "    'redu_kernel'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return rku(d_dist, f_0, mean, sigma, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(nll(.5,.5,.5,.5)) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "float(nll(*np.random.rand(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d_dist = torch.tensor(dist, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * torch.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -torch.sum(torch.log(add(d_dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = nll(.5,.5,.5,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert v.item() == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow: static graphs\n",
    "\n",
    "Eager execution is broken for me due to incompatibilty with LZ4. Also tensorflow doesn't play nice with memory, so restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/tf.sqrt(2*np.pi*σ**2) * tf.math.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nll(d_dist, f_0, mean, sigma, sigma2):\n",
    "    return -tf.reduce_sum(tf.math.log(add(d_dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(dist)\n",
    "tf_f_0 = tf.placeholder(dtype=tf.float64)\n",
    "tf_mean = tf.placeholder(dtype=tf.float64)\n",
    "tf_sigma = tf.placeholder(dtype=tf.float64)\n",
    "tf_sigma2 = tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "graph = make_nll(x, tf_f_0, tf_mean, tf_sigma, tf_sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "def nll(f_0, mean, sigma, sigma2): \n",
    "    loss_value = sess.run(graph,\n",
    "                          feed_dict={tf_f_0:f_0,\n",
    "                                     tf_mean:mean,\n",
    "                                     tf_sigma:sigma,\n",
    "                                     tf_sigma2:sigma2})\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random numbers here just to make sure we don't get some special caching or somthing from TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using tensorflow, be a good user and kill the kernel so GPU memory gets reclaimed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of summation algorithms:\n",
    "\n",
    "```python\n",
    ">>> import numpy as np\n",
    ">>> import math\n",
    ">>> np.random.seed(42)\n",
    ">>> dist = np.hstack([\n",
    "...     np.random.normal(loc=1, scale=2., size=500_000),\n",
    "...     np.random.normal(loc=1, scale=.5, size=500_000)\n",
    "... ])\n",
    "\n",
    "# fsum vs. naive\n",
    ">>> math.fsum(dist) - sum(dist)\n",
    "5.820766091346741e-10\n",
    "\n",
    "# fsum vs. np.sum\n",
    ">>> math.fsum(dist) - np.sum(dist)\n",
    "0.0\n",
    "\n",
    "# Check with 32 bit, fsum vs. naive\n",
    ">>> math.fsum(dist.astype(np.float32)) - sum(dist.astype(np.float32), np.float32(0))\n",
    "-20.27040922746528\n",
    "\n",
    "# Check with 32 bit, fsum vs. np.sum\n",
    ">>> math.fsum(dist.astype(np.float32)) - np.sum(dist.astype(np.float32))\n",
    "-0.1454092274652794\n",
    "\n",
    "# Check with 32 bit fsum vs. 64 bit fsum\n",
    ">>> math.fsum(dist) - math.fsum(dist.astype(np.float32))\n",
    "-2.3222528398036957e-06\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
