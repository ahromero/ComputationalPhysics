{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12 Day 1: Requested topic: Fitting\n",
    "\n",
    "## Objectives:\n",
    "* Cover performance and syntax for general unbinned fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to `pip install probfit` (`--user` if you are not in a virtual environment). `cupy` is used at the end; you'll need `conda install cupy` in an environment. Times are from a 24 core Xeon with a Titan V."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will put our preperation code in a file, and restart the kernel as we go, just to make sure we don't have any interaction between GPU libraries. `likelyhood_answer` is defined to be the numpy value - Note that the reduction can produce lots of round of error if not done properly. I know numpy does, not sure about probfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results: \n",
    "    \n",
    "| Package   | Hardware      | Time per call | Minimize time |\n",
    "|-----------|---------------|---------------|---------------|\n",
    "| Probfit   | 24 core Zeon  | 1.11 s        | 2.23 min      |\n",
    "| Numpy     | 24 core Zeon  | 21.1 ms       | 2.38 s        |\n",
    "| Numba parallel | 24 core Zeon | 11.5 ms   | 1.46 s        |\n",
    "| Numba parallel loop | 24 core Zeon | 3.68 ms | 416 ms     |\n",
    "| GooFit    | Titan V       | 2.30 ms       | 333 ms        |\n",
    "| CUPY      | Titan V       | 2.9 ms        | 491 ms        |\n",
    "| CUPY kernel | Titan V     | 843 µs        | 118 ms        |\n",
    "| CUPY redu | Titan V       | 2.50 ms       | 343 ms        |\n",
    "| PyTorch   | Titan V       | 3.68 ms       | 594 ms        |\n",
    "| TensorFlow static | Titan V | 1.38 ms     | 225 ms        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_pretty import read_pretty\n",
    "read_pretty('common.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data\n",
    "\n",
    "First, we make our data. It's a simple double gaussian with no background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist, bins='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probfit\n",
    "\n",
    "Now, let's try using probfit to fit the data. First, we have to rename the parameters - probfit merges similar named parameters. I already know that gaussian comes with `x`, `mean`, and `sigma`. We use `AddPdfNorm` to add the pdfs, and they are kept normalized. A new parameter is added, `f_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import probfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_gaussian = probfit.rename(probfit.gaussian, [\"x\", \"mean\", \"sigma2\"])\n",
    "pdf_function = probfit.AddPdfNorm(probfit.gaussian, second_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build an unbinned likelyhood function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbinned_lh = probfit.UnbinnedLH(pdf_function, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unbinned_lh(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "unbinned_lh(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use iMinuit's name based parameter setting interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(unbinned_lh, **default_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's do the fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbinned_lh.draw(minuit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GooFit\n",
    "\n",
    "Let's try that in GooFit. We set up our model in what I view as a more readable but more verbose way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import goofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goofit.GOOFIT_DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = goofit.Observable('x', -10, 10)\n",
    "\n",
    "ds = goofit.UnbinnedDataSet(x)\n",
    "ds.from_matrix([dist], filter=True)\n",
    "\n",
    "mean = goofit.Variable('mean', 1.5, -10, 10)\n",
    "sigma = goofit.Variable('sigma', .4, 0, 1)\n",
    "sigma2 = goofit.Variable('sigma2', 3, 1, 3)\n",
    "f_0 = goofit.Variable('f_0', .5, 0, 1)\n",
    "\n",
    "gauss1 = goofit.GaussianPdf(\"gauss1\", x, mean, sigma)\n",
    "gauss2 = goofit.GaussianPdf(\"gauss2\", x, mean, sigma2)\n",
    "\n",
    "pdf = goofit.AddPdf('pdf', [f_0], [gauss1, gauss2])\n",
    "\n",
    "pdf.fitTo(ds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: On a single thread CPU build, this is about 7-10x faster than probfit. This is on a Titan V GPU, so it's a lot more than that.\n",
    "\n",
    "Plotting is a bit more verbose, but not too bad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, points = pdf.evaluatePdf(x)\n",
    "xs = grid.to_matrix().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(xs, points)\n",
    "ax.hist(dist, bins='auto', density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "Let's try this with Numpy and iMinuit. We could use probfit to make the NLL, but it's much faster to do it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "I originally used numba here, but since this is all done in array form, even parallel Numba is only a small fraction (10-30%) faster on my laptop. On a 24 core Xeon, however... You'll see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * np.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -np.sum(np.log(add(dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Numpy uses a good definition of a sum, while Python's built in sum has rounding point errors. This would be more important if we used fewer bits. Let's compare: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reduction sum:\n",
    "assert -sum(np.log(add(dist, .5, .5, .5, .5))) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check floating point accurate sum:\n",
    "assert -math.fsum(np.log(add(dist, .5, .5, .5, .5))) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much (2-3x) slower if we use this in Minuit\n",
    "# unbinned_lh = probfit.UnbinnedLH(add, dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba\n",
    "\n",
    "Let's use Numba's parallel abilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * np.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -np.sum(np.log(add(dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numba Parallel loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * np.exp(-(x-μ)**2/(2*σ**2))\n",
    "\n",
    "@numba.jit\n",
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def nllp(dist, f_0, mean, sigma, sigma2):\n",
    "    s = 0.0\n",
    "    for i in numba.prange(len(dist)):\n",
    "        s +=  np.log(add(dist[i], f_0, mean, sigma, sigma2))\n",
    "    return -s\n",
    "    \n",
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return nllp(dist, f_0, mean, sigma, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUPY GPU\n",
    "\n",
    "Let's use CUPY on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d_dist = cupy.array(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/cupy.sqrt(2*np.pi*σ**2) * cupy.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -cupy.sum(cupy.log(add(d_dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(nll(.5,.5,.5,.5)) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "float(nll(*np.random.rand(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cupy Custom Kernel\n",
    "\n",
    "Let's go all out and write a CUDA kernel by hand, then call sum on it. We are *almost* ideal here; the only downside is that we make a single temporary 1M element array before summing.\n",
    "\n",
    "We *could* use a reduction kernel, but I don't know if I trust that do not have round off error issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mykernel = cupy.ElementwiseKernel(\n",
    "    'float64 x, float64 f_0, float64 mean, float64 sigma, float64 sigma2',\n",
    "    'float64 z', '''\n",
    "    \n",
    "    double s12 = 2*sigma*sigma;\n",
    "    double s22 = 2*sigma2*sigma2;\n",
    "    \n",
    "    double p = -(x-mean)*(x-mean);\n",
    "    double g = rsqrt(M_PI*s12) * exp(p/s12);\n",
    "    double g2 = rsqrt(M_PI*s22) * exp(p/s22);\n",
    "    \n",
    "    z = log(f_0 * g + (1 - f_0) * g2);\n",
    "        \n",
    "    ''', 'mykernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -cupy.sum(mykernel(d_dist, f_0, mean, sigma, sigma2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(nll(.5,.5,.5,.5)) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "float(nll(*np.random.rand(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rku = cupy.ReductionKernel(\n",
    "    'float64 x, float64 f_0, float64 mean, float64 sigma, float64 sigma2',\n",
    "    'float64 r',\n",
    "    '''\n",
    "    log(     f_0  * rsqrt(2*M_PI*sigma*sigma)   * exp(-(x-mean)*(x-mean)/(2*sigma*sigma)) +\n",
    "        (1 - f_0) * rsqrt(2*M_PI*sigma2*sigma2) * exp(-(x-mean)*(x-mean)/(2*sigma2*sigma2)))\n",
    "    ''',\n",
    "    'a + b',\n",
    "    'r = -a',\n",
    "    '0',\n",
    "    'redu_kernel'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return rku(d_dist, f_0, mean, sigma, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(nll(.5,.5,.5,.5)) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "float(nll(*np.random.rand(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d_dist = torch.tensor(dist, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * torch.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(f_0, mean, sigma, sigma2):\n",
    "    return -torch.sum(torch.log(add(d_dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = nll(.5,.5,.5,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert v.item() == likelyhood_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow: static graphs\n",
    "\n",
    "Eager execution is broken for me due to incompatibilty with LZ4. Also tensorflow doesn't play nice with memory, so restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/tf.sqrt(2*np.pi*σ**2) * tf.math.exp(-(x-μ)**2/(2*σ**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nll(d_dist, f_0, mean, sigma, sigma2):\n",
    "    return -tf.reduce_sum(tf.math.log(add(d_dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(dist)\n",
    "tf_f_0 = tf.placeholder(dtype=tf.float64)\n",
    "tf_mean = tf.placeholder(dtype=tf.float64)\n",
    "tf_sigma = tf.placeholder(dtype=tf.float64)\n",
    "tf_sigma2 = tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "graph = make_nll(x, tf_f_0, tf_mean, tf_sigma, tf_sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "def nll(f_0, mean, sigma, sigma2): \n",
    "    loss_value = sess.run(graph,\n",
    "                          feed_dict={tf_f_0:f_0,\n",
    "                                     tf_mean:mean,\n",
    "                                     tf_sigma:sigma,\n",
    "                                     tf_sigma2:sigma2})\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nll(.5,.5,.5,.5) == likelyhood_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random numbers here just to make sure we don't get some special caching or somthing from TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(*np.random.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit = Minuit(nll,\n",
    "                errordef=1,\n",
    "                **default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_and_print(minuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using tensorflow, be a good user and kill the kernel so GPU memory gets reclaimed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of summation algorithms:\n",
    "\n",
    "```python\n",
    ">>> import numpy as np\n",
    ">>> import math\n",
    ">>> np.random.seed(42)\n",
    ">>> dist = np.hstack([\n",
    "...     np.random.normal(loc=1, scale=2., size=500_000),\n",
    "...     np.random.normal(loc=1, scale=.5, size=500_000)\n",
    "... ])\n",
    "\n",
    "# fsum vs. naive\n",
    ">>> math.fsum(dist) - sum(dist)\n",
    "5.820766091346741e-10\n",
    "\n",
    "# fsum vs. np.sum\n",
    ">>> math.fsum(dist) - np.sum(dist)\n",
    "0.0\n",
    "\n",
    "# Check with 32 bit, fsum vs. naive\n",
    ">>> math.fsum(dist.astype(np.float32)) - sum(dist.astype(np.float32), np.float32(0))\n",
    "-20.27040922746528\n",
    "\n",
    "# Check with 32 bit, fsum vs. np.sum\n",
    ">>> math.fsum(dist.astype(np.float32)) - np.sum(dist.astype(np.float32))\n",
    "-0.1454092274652794\n",
    "\n",
    "# Check with 32 bit fsum vs. 64 bit fsum\n",
    ">>> math.fsum(dist) - math.fsum(dist.astype(np.float32))\n",
    "-2.3222528398036957e-06\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
